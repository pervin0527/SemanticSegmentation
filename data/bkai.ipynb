{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/pervinco/SemanticSegmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils.utils import Args\n",
    "from data.util import mask_encoding, mask_decoding, get_bbox_from_mask\n",
    "from data.augmentation import basic_transform, mosaic, sep, apply_transform, get_bg_image, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/pervinco/Datasets/BKAI-IGH-NeoPolyp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "image_files = sorted(glob(f\"{data_dir}/train/train/*\"))\n",
    "mask_files = sorted(glob(f\"{data_dir}/train_gt/train_gt/*\"))\n",
    "\n",
    "print(len(image_files), len(mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "image_file = image_files[idx]\n",
    "mask_file = mask_files[idx]\n",
    "print(image_file, mask_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_file)\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(image.shape, mask.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "unique_values = np.unique(gray_mask)\n",
    "print(f\"Unique pixel values in the mask: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_value = 69\n",
    "class_mask = gray_mask >= class_value\n",
    "\n",
    "plt.imshow(class_mask, cmap='gray')\n",
    "plt.title(f\"Mask for class {class_value}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때, [0, 1] 또는 [0, 2]로 구성되지 않고 여러 가지 값들로 구성되어 있음을 볼 수 있다. 결과적으로 마스크 픽셀에 대한 정제가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Mask Encoding & Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제를 해결하기 위해 encoding, decoding 함수 정의.\n",
    "\n",
    "- encoding : HSV 기준 픽셀이 지정된 범위 내에 있는 픽셀인 경우 클래스 1(non-neoplastic polyps), 클래스 2(neoplastic polyps)로 처리. 즉, [0, 1, 2]로 구성되는 binary mask\n",
    "- decoding : 인코딩된 마스크를 보고 RGB 픽셀로 맵핑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_encoding(mask, red_threshold=0.6, green_threshold=0.6):\n",
    "    # Convert BGR mask to HSV\n",
    "    hsv_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define thresholds for red and green channels in BGR\n",
    "    red_lower = np.array([0, 100, 100])\n",
    "    red_upper = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([160, 100, 100])\n",
    "    red_upper2 = np.array([179, 255, 255])\n",
    "    green_lower = np.array([35, 100, 100])\n",
    "    green_upper = np.array([85, 255, 255])\n",
    "\n",
    "    # Create masks for red and green colors\n",
    "    red_mask1 = cv2.inRange(hsv_mask, red_lower, red_upper)\n",
    "    red_mask2 = cv2.inRange(hsv_mask, red_lower2, red_upper2)\n",
    "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "    green_mask = cv2.inRange(hsv_mask, green_lower, green_upper)\n",
    "\n",
    "    # Initialize full_mask with zeros\n",
    "    full_mask = np.zeros_like(red_mask)\n",
    "\n",
    "    # Set red pixels to 1 and green pixels to 2\n",
    "    full_mask[red_mask > 0] = 2\n",
    "    full_mask[green_mask > 0] = 1\n",
    "\n",
    "    return full_mask\n",
    "\n",
    "\n",
    "def mask_decoding(pred_mask):\n",
    "    decoded_mask = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n",
    "    decoded_mask[pred_mask == 0] = [0, 0, 0]\n",
    "    decoded_mask[pred_mask == 1] = [0, 255, 0] ## Green\n",
    "    decoded_mask[pred_mask == 2] = [255, 0, 0] ## Red\n",
    "    \n",
    "    return decoded_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "image_file = image_files[idx]\n",
    "mask_file = mask_files[idx]\n",
    "print(image_file, mask_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_file)\n",
    "# mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "encoded_mask = mask_encoding(mask)\n",
    "print(encoded_mask.shape)\n",
    "print(np.unique(encoded_mask))\n",
    "\n",
    "plt.imshow(encoded_mask, cmap=\"gray\")\n",
    "plt.title(\"Encoded mask\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_mask = mask_decoding(encoded_mask)\n",
    "print(decoded_mask.shape)\n",
    "print(np.unique(decoded_mask))\n",
    "\n",
    "plt.imshow(decoded_mask)\n",
    "plt.title(\"Decoded mask\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"{data_dir}/train_mask\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for mask_file in mask_files:\n",
    "    file_name = mask_file.split('/')[-1].split('.')[0]\n",
    "    mask = cv2.imread(mask_file)\n",
    "    encoded_mask = mask_encoding(mask)\n",
    "    decoded_mask = mask_decoding(encoded_mask)\n",
    "    decoded_mask = cv2.cvtColor(decoded_mask, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(f\"{save_dir}/{file_name}.jpeg\", decoded_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 클래스의 분포를 확인하기 위해 인코딩 마스크를 기반으로 구분한다.\n",
    "- 1만 존재하는 마스크.\n",
    "- 2만 존재하는 마스크.\n",
    "- 1과 2가 동시에 존재하는 마스크."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_masks(mask_files):\n",
    "    red_masks = []\n",
    "    green_masks = []\n",
    "    red_and_green_masks = []\n",
    "    \n",
    "    for mask_file in mask_files:\n",
    "        file_name = mask_file.split(\"/\")[-1].split(\".\")[0]\n",
    "        mask = cv2.imread(mask_file)\n",
    "        encoded_mask = mask_encoding(mask)\n",
    "        \n",
    "        has_green = np.any(encoded_mask == 1)\n",
    "        has_red = np.any(encoded_mask == 2)\n",
    "        \n",
    "        if has_green and not has_red:\n",
    "            green_masks.append(file_name)\n",
    "        elif has_red and not has_green:\n",
    "            red_masks.append(file_name)\n",
    "        elif has_green and has_red:\n",
    "            red_and_green_masks.append(file_name)\n",
    "    \n",
    "    with open(f'{data_dir}/files/red.txt', 'w') as file:\n",
    "        for item in red_masks:\n",
    "            file.write(f\"{item}\\n\")\n",
    "            \n",
    "    with open(f'{data_dir}/files/green.txt', 'w') as file:\n",
    "        for item in green_masks:\n",
    "            file.write(f\"{item}\\n\")\n",
    "            \n",
    "    with open(f'{data_dir}/files/red_and_green.txt', 'w') as file:\n",
    "        for item in red_and_green_masks:\n",
    "            file.write(f\"{item}\\n\")\n",
    "    \n",
    "    print(len(red_masks), len(green_masks), len(red_and_green_masks))\n",
    "    labels = ['Red Only', 'Green Only', 'Red and Green']\n",
    "    counts = [len(red_masks), len(green_masks), len(red_and_green_masks)]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(labels, counts, color=['red', 'green', 'orange'])\n",
    "    plt.title('Mask Type Distribution')\n",
    "    plt.xlabel('Mask Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{data_dir}/files\"):\n",
    "    os.makedirs(f\"{data_dir}/files\")\n",
    "    \n",
    "sort_masks(mask_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split Train/Valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_list(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_masks = read_file_list(f'{data_dir}/files/red.txt')\n",
    "green_masks = read_file_list(f'{data_dir}/files/green.txt')\n",
    "red_and_green_masks = read_file_list(f'{data_dir}/files/red_and_green.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 1과 2가 동시에 존재하는 경우 균등 분배\n",
    "half_red_and_green = int(len(red_and_green_masks) * 0.1)\n",
    "valid_red_and_green = red_and_green_masks[:half_red_and_green]\n",
    "train_red_and_green = red_and_green_masks[half_red_and_green:]\n",
    "\n",
    "# 클래스 1과 클래스 2의 1대1 비율을 유지하기 위한 작업\n",
    "# 가능한 한 많은 클래스 1 데이터를 유지하기 위해, validation set에 클래스 1 데이터를 먼저 할당\n",
    "valid_green = green_masks[:len(red_masks)//10]\n",
    "train_green = green_masks[len(red_masks)//10:]\n",
    "\n",
    "# 클래스 2 데이터 중 validation set에 할당되지 않은 나머지를 train set에 할당\n",
    "valid_red = red_masks[:len(valid_green)]  # validation에 할당된 클래스 1 데이터와 같은 양의 클래스 2 데이터를 validation에 할당\n",
    "train_red = red_masks[len(valid_green):]\n",
    "\n",
    "# 최종 train set과 validation set 구성\n",
    "train_files = train_red + train_green + train_red_and_green\n",
    "valid_files = valid_red + valid_green + valid_red_and_green\n",
    "\n",
    "# 결과를 파일에 기록\n",
    "with open(f'{data_dir}/files/train.txt', 'w') as file:\n",
    "    for item in train_files:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "with open(f'{data_dir}/files/valid.txt', 'w') as file:\n",
    "    for item in valid_files:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "print(f\"Train set size: {len(train_files)}, Validation set size: {len(valid_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = {\n",
    "    'red': len(train_red),\n",
    "    'green': len(train_green),\n",
    "    'red_and_green': len(train_red_and_green)\n",
    "}\n",
    "\n",
    "valid_counts = {\n",
    "    'red': len(valid_red),\n",
    "    'green': len(valid_green),\n",
    "    'red_and_green': len(valid_red_and_green)\n",
    "}\n",
    "\n",
    "labels = ['Red', 'Green', 'Red and Green']\n",
    "train_values = [train_counts['red'], train_counts['green'], train_counts['red_and_green']]\n",
    "valid_values = [valid_counts['red'], valid_counts['green'], valid_counts['red_and_green']]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "train_bars = ax.bar(x - width/2, train_values, width, label='Train')\n",
    "valid_bars = ax.bar(x + width/2, valid_values, width, label='Valid')\n",
    "\n",
    "ax.set_xlabel('Classes')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Counts of Red, Green, and Red_and_Green in Train and Valid Sets')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_and_save_files(red_masks, green_masks, red_and_green_masks):\n",
    "#     half_index_red_and_green = len(red_and_green_masks) // 2\n",
    "#     train_red_and_green = red_and_green_masks[:half_index_red_and_green]\n",
    "#     valid_red_and_green = red_and_green_masks[half_index_red_and_green:]\n",
    "\n",
    "#     available_class_2_for_valid = len(green_masks) - (len(red_masks) - len(valid_red_and_green))    \n",
    "#     valid_class_1_amount = min(len(green_masks) // 4, available_class_2_for_valid)\n",
    "    \n",
    "#     valid_green = green_masks[:valid_class_1_amount]\n",
    "#     train_green = green_masks[valid_class_1_amount:]\n",
    "    \n",
    "#     valid_red = red_masks[:valid_class_1_amount + len(valid_red_and_green)]\n",
    "#     train_red = red_masks[valid_class_1_amount + len(valid_red_and_green):]\n",
    "\n",
    "#     def save_to_file(file_list, file_name):\n",
    "#         with open(file_name, 'w') as file:\n",
    "#             for item in file_list:\n",
    "#                 file.write(f\"{item}\\n\")\n",
    "\n",
    "#     save_to_file(train_red, f'{data_dir}/files/train_red.txt')\n",
    "#     save_to_file(valid_red, f'{data_dir}/files/valid_red.txt')\n",
    "#     save_to_file(train_green, f'{data_dir}/files/train_green.txt')\n",
    "#     save_to_file(valid_green, f'{data_dir}/files/valid_green.txt')\n",
    "#     save_to_file(train_red_and_green, f'{data_dir}/files/train_red_and_green.txt')\n",
    "#     save_to_file(valid_red_and_green, f'{data_dir}/files/valid_red_and_green.txt')\n",
    "\n",
    "\n",
    "# split_and_save_files(red_masks, green_masks, red_and_green_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(data_dir, \"train_boxes/train_boxes\")):\n",
    "    os.makedirs(os.path.join(data_dir, \"train_boxes/train_boxes\"))\n",
    "if not os.path.exists(os.path.join(data_dir, \"train_boxes/samples\")):\n",
    "    os.makedirs(os.path.join(data_dir, \"train_boxes/samples\"))\n",
    "\n",
    "for image_file, mask_file in zip(image_files, mask_files):\n",
    "    file_name = os.path.basename(mask_file).split('.')[0]\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = cv2.imread(mask_file)\n",
    "    encoded_mask = mask_encoding(mask)\n",
    "\n",
    "    bboxes_dict = get_bbox_from_mask(encoded_mask)\n",
    "    sample_image = image.copy()  # 이미지 복사본 생성\n",
    "    for class_id, bboxes in bboxes_dict.items():\n",
    "        bbox_file_path = os.path.join(data_dir, \"train_boxes/train_boxes\", f\"{file_name}.txt\")\n",
    "        with open(bbox_file_path, \"w\") as f:\n",
    "            for bbox in bboxes:\n",
    "                # 파일에 `class_idx xmin ymin xmax ymax` 형태로 기록\n",
    "                bbox_str = ' '.join(map(str, [class_id] + list(bbox)))\n",
    "                f.write(f\"{bbox_str}\\n\")\n",
    "\n",
    "                # 이미지에 바운딩 박스 그리기\n",
    "                xmin, ymin, xmax, ymax = bbox\n",
    "                cv2.rectangle(sample_image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    # 바운딩 박스가 그려진 이미지를 samples 폴더에 저장\n",
    "    sample_image_path = os.path.join(data_dir, \"train_boxes/samples\", f\"{file_name}.jpg\")\n",
    "    cv2.imwrite(sample_image_path, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(f\"{data_dir}/train_boxes/train_boxes\"):\n",
    "#     os.makedirs(f\"{data_dir}/train_boxes/train_boxes\")\n",
    "\n",
    "# for image_file, mask_file in zip(image_files, mask_files):\n",
    "#     file_name = mask_file.split('/')[-1].split('.')[0]\n",
    "#     mask = cv2.imread(mask_file)\n",
    "#     encoded_mask = mask_encoding(mask)\n",
    "\n",
    "#     bboxes_dict = get_bbox_from_mask(encoded_mask)  # 바운딩 박스 정보가 담긴 딕셔너리\n",
    "#     print(bboxes_dict)\n",
    "    \n",
    "#     # 딕셔너리의 각 값(value)에 해당하는 바운딩 박스 리스트를 순회\n",
    "#     for class_id, bboxes in bboxes_dict.items():\n",
    "#         with open(f\"{data_dir}/train_boxes/train_boxes/{file_name}_{class_id}.txt\", \"w\") as f:\n",
    "#             for bbox in bboxes:\n",
    "#                 bbox_str = ' '.join(map(str, bbox))\n",
    "#                 f.write(f\"{bbox_str}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BKAIDataset(Dataset):\n",
    "    CLASSES = [\"background\", \"non-neoplastic polyps\", \"neoplastic polyps\"]\n",
    "    COLORMAP = [[0, 0, 0], [0, 255, 0], [255, 0, 0]]\n",
    "\n",
    "    def __init__(self, args, feature_extractor=None, image_set=\"train\"):\n",
    "        self.args = args\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.is_train = True if image_set == \"train\" else False\n",
    "        \n",
    "        self.data_dir = args.data_dir\n",
    "        self.image_dir = f\"{self.data_dir}/train/train\"\n",
    "        self.mask_dir = f\"{self.data_dir}/train_gt/train_gt\"\n",
    "        self.bbox_dir = f\"{self.data_dir}/train_boxes/train_boxes\"\n",
    "        self.transform = basic_transform(is_train=self.is_train, img_size=args.img_size)\n",
    "\n",
    "        with open(f\"{self.data_dir}/files/{image_set}.txt\", 'r') as f:\n",
    "            self.total_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.bg_files = glob(f\"{self.data_dir}/background/0_normal/*.jpg\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_files)\n",
    "\n",
    "    def get_img_mask(self, file_name):\n",
    "        image_path = f\"{self.image_dir}/{file_name}.jpeg\"\n",
    "        mask_path = f\"{self.mask_dir}/{file_name}.jpeg\"\n",
    "        bbox_path = f\"{self.bbox_dir}/{file_name}.txt\"\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        \n",
    "        labels = []\n",
    "        bboxes = []\n",
    "        if os.path.exists(bbox_path):\n",
    "            with open(bbox_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    label, xmin, ymin, xmax, ymax = map(int, line.strip().split())\n",
    "                    labels.append(label)\n",
    "                    bboxes.append((xmin, ymin, xmax, ymax))\n",
    "                    \n",
    "        return image, mask, bboxes, labels\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            p = random.random()\n",
    "            if p < 0.3:\n",
    "                file_name = self.total_files[idx]\n",
    "                image, mask, bboxes, labels = self.get_img_mask(file_name)\n",
    "                batch_image, batch_mask, batch_bboxes, batch_labels = apply_transform(image, mask, bboxes, labels, self.transform)\n",
    "\n",
    "                if random.random() > 0.7:\n",
    "                    background_image = get_bg_image(self.bg_files)\n",
    "                    batch_image = mixup(batch_image, background_image, img_size=self.args.img_size, alpha=random.uniform(self.args.mixup_alpha, self.args.mixup_alpha + 0.3))\n",
    "\n",
    "            elif 0.3 < p <= 0.6:\n",
    "                piecies = []\n",
    "                while len(piecies) < 4:\n",
    "                    i = random.randint(0, len(self.total_files)-1)\n",
    "                    file_name = self.total_files[i]\n",
    "                    image, mask, bboxes, labels = self.get_img_mask(file_name)\n",
    "\n",
    "                    if random.random() > 0.5:\n",
    "                        piece_image, piece_mask, batch_bboxes, batch_labels = apply_transform(image, mask, bboxes, labels, self.transform)\n",
    "                    else:\n",
    "                        piece_image, piece_mask = sep(image, mask, self.args.img_size, alpha=random.uniform(self.args.spatial_alpha, self.args.spatial_alpha + 0.2))\n",
    "\n",
    "                    piecies.append([piece_image, piece_mask])\n",
    "\n",
    "                batch_image, batch_mask = mosaic(piecies, size=self.args.img_size)\n",
    "                if random.random() > 0.7:\n",
    "                    background_image = get_bg_image(self.bg_files)\n",
    "                    piece_image = mixup(batch_image, background_image, img_size=self.args.img_size, alpha=random.uniform(self.args.mixup_alpha, self.args.mixup_alpha + 0.3))\n",
    "\n",
    "            elif 0.6 < p <= 1:\n",
    "                file_name = self.total_files[idx]\n",
    "                image, mask, bboxes, labels = self.get_img_mask(file_name)\n",
    "                batch_image, batch_mask = sep(image, mask, self.args.img_size, alpha=random.uniform(self.args.spatial_alpha, self.args.spatial_alpha + 0.2))\n",
    "\n",
    "                if random.random() > 0.7:\n",
    "                    background_image = get_bg_image(self.bg_files)\n",
    "                    batch_image = mixup(batch_image, background_image, img_size=self.args.img_size, alpha=random.uniform(self.args.mixup_alpha, self.args.mixup_alpha + 0.3))\n",
    "                \n",
    "        else:\n",
    "            file_name = self.total_files[idx]\n",
    "            image, mask, bboxes, labels = self.get_img_mask(file_name)\n",
    "            batch_image, batch_mask, batch_bboxes, batch_labels = apply_transform(image, mask, bboxes, labels, self.transform)\n",
    "\n",
    "        batch_mask = mask_encoding(batch_mask)\n",
    "        if self.feature_extractor is not None:\n",
    "            encoded_inputs = self.feature_extractor(batch_image, batch_mask, return_tensors=\"pt\")\n",
    "            for k, v in encoded_inputs.items():\n",
    "                encoded_inputs[k].squeeze_()\n",
    "\n",
    "            return encoded_inputs   \n",
    "        \n",
    "        else:\n",
    "            return batch_image, batch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\"/home/pervinco/SemanticSegmentation/config.yaml\", is_train=False)\n",
    "dataset = BKAIDataset(args, image_set=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset_sample(dataset, idx):\n",
    "    image, encoded_mask = dataset[idx]\n",
    "    \n",
    "    # image = image.numpy().transpose((1, 2, 0))\n",
    "    # mean = np.array([0.485, 0.456, 0.406])\n",
    "    # std = np.array([0.229, 0.224, 0.225])\n",
    "    # image = std * image + mean\n",
    "    # image = np.clip(image, 0, 1)\n",
    "    \n",
    "    decoded_mask = mask_decoding(encoded_mask)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(decoded_mask)\n",
    "    axes[1].set_title('Decoded Mask')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset_sample(dataset, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_workers = os.cpu_count()\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{data_dir}/batch_images\"):\n",
    "    os.makedirs(f\"{data_dir}/batch_images\")\n",
    "\n",
    "for i, (images, masks) in enumerate(dataloader):\n",
    "    print(images.shape, masks.shape)\n",
    "    if i == 10:\n",
    "        break\n",
    "    images, masks = images.numpy(), masks.numpy()\n",
    "    for j, (image, mask) in enumerate(zip(images, masks)):\n",
    "        mask = mask_decoding(mask)\n",
    "\n",
    "        overlay = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n",
    "        result = np.hstack((image, mask, overlay))\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        cv2.imwrite(f\"{data_dir}/batch_images/batch{i}_no{j}.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
